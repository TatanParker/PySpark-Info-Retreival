{"cells":[{"cell_type":"markdown","source":["# Motor de recomendación con PySpark"],"metadata":{}},{"cell_type":"markdown","source":["___\n## Tarea 1 - Módulo 8\n\nLa práctica consiste en construir un recomendador con el módulo de recomendación de Spark (en la versión 1.6 solamente implementa el método ALS) sobre un conjunto de entrenamiento, realizar predicciones sobre un conjunto de test y posteriormente evaluar su rendimiento aplicando un RegressionEvaluator con metricName=”rmse”, dado que los valores finales son las valoraciones que se supone que daría el usuario a una determinada película que aún no ha visto, y por tanto numéricos.\n\nEl paquete de pySpark de recomendaciones se encuentra en:\n\nhttp://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS\n\nEl recomendador se construirá utilizando el dataset de 100000 puntuaciones de 1000 usuarios sobre 1700 películas de Movielens\n\nhttp://grouplens.org/datasets/movielens/100k/  (user id | item id | rating | timestamp)\n\nSe recomienda leer el archivo README.txt para entender bien los datos:\n\nhttp://files.grouplens.org/datasets/movielens/ml-100k-README.txt\n\n\nEl entregable será un notebook de Python con el código pyspark correspondiente."],"metadata":{}},{"cell_type":"markdown","source":["___\n## Preparación del entorno: paquetes y variables\n\nLo primero que vamos hacer es **importar todos los paquetes** necesarios y crear el contexto para los data frames (SQLContext)"],"metadata":{}},{"cell_type":"code","source":["import re\nfrom pyspark.sql import SQLContext, Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.recommendation import ALS, ALSModel\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\nsqlc = SQLContext(sc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["A continuación se crean las **variables** para:\n* Las rutas y nombres de los siguientes ficheros: puntuaciones usuario-película, información de los usuarios, información de las películas, información de las categorías de las películas\n* El separador de los campos en los ficheros que pueden ser un pipe o un tabulador\n* El nombre y posición de las columnas de los ficheros; además del tipo de dato que será en el dataframe"],"metadata":{}},{"cell_type":"code","source":["# Rutas, nombres de los datasets y separadores que se usan\n\nRUTA_FICHERO_PUNTUACION = '/FileStore/tables/u.data'\nRUTA_FICHERO_USUARIO = '/FileStore/tables/u.user'\nRUTA_FICHERO_ITEM = '/FileStore/tables/u.item'\nRUTA_FICHERO_GENERO = '/FileStore/tables/u.genre'\nSEPARADOR_TABULADOR = '\\t'\nSEPARADOR_PIPE = '|'\n\n# Variables con información de las columnas de los ficheros: \n#    - posicion 0: nombre de la columna en el fichero\n#    - posicion 1: posicion de la columna en el fichero\n#    - posicion 2: tipo dataframe\n#    - posicion 3: True si la columna puede ser nullable. Se utilizara al convertir de RDD a dataframe.\n# Se crea también una lista con ellos dentro por si se quiere iterar\n\n\n# Dataset de puntuaciones\n\nCOL_PUNTUACION_USERID = ('userid', 0, IntegerType(), True)\nCOL_PUNTUACION_ITEMID = ('itemid', 1, IntegerType(), True)\nCOL_PUNTUACION_RATING = ('rating', 2, FloatType(), True)\nCOL_PUNTUACION_TIMESTAMP = ('timestamp', 3, IntegerType(), True)\nCOL_PUNTUACION_PREDICTION = ('prediction', None, None, None)\nCOL_PUNTUACION_NUMEROPUNTUACIONES = ('numero_puntuaciones', None, None, None)\nCOLS_PUNTUACION = (\n    COL_PUNTUACION_USERID, \n    COL_PUNTUACION_ITEMID, \n    COL_PUNTUACION_RATING, \n    COL_PUNTUACION_TIMESTAMP)\n\n# Dataset de usuarios\n\nCOL_USUARIO_ID = ('user_userid', 0, IntegerType(), True)\nCOL_USUARIO_AGE = ('age', 1, IntegerType(), True)\nCOL_USUARIO_GENDER = ('gender', 2, StringType(), True)\nCOL_USUARIO_OCCUPATION = ('occupation', 3, StringType(), True)\nCOL_USUARIO_ZIPCODE = ('zipcode', 4, StringType(), True)\nCOLS_USUARIO = (\n    COL_USUARIO_ID, \n    COL_USUARIO_AGE, \n    COL_USUARIO_GENDER, \n    COL_USUARIO_OCCUPATION,\n    COL_USUARIO_ZIPCODE)\n\n#  Dataset de generos\n\nCOL_GENERO_NAME = ('name', 0, StringType(), False)\nCOL_GENERO_ID = ('genre_genreid', 1, IntegerType(), False)\nCOLS_GENERO = (\n    COL_GENERO_NAME, \n    COL_GENERO_ID)\n\n#  Dataset de items\n\nCOL_ITEM_ID = ('item_itemid', 0, IntegerType(), False)\nCOL_ITEM_TITLE = ('title', 1, StringType(), False)\nCOL_ITEM_RELEASEDATE = ('releasedate', 2, StringType(), False)\nCOL_ITEM_VIDERELEASEDATE = ('videoreleasedate', 3, StringType(), False)\nCOL_ITEM_IMDBURL = ('imdburl', 4, StringType(), False)\nCOL_ITEM_UNKNOWN = ('unknown', 5, IntegerType(), False)\nCOL_ITEM_ACTION = ('action', 6, IntegerType(), False)\nCOL_ITEM_ADVENTURE = ('adventure', 7, IntegerType(), False)\nCOL_ITEM_ANIMATION = ('animation', 8, IntegerType(), False)\nCOL_ITEM_CHILDRENS = ('childrens', 9, IntegerType(), False)\nCOL_ITEM_COMEDY = ('comedy', 10, IntegerType(), False)\nCOL_ITEM_CRIME = ('crime', 11, IntegerType(), False)\nCOL_ITEM_DOCUMENTARY = ('documentary', 12, IntegerType(), False)\nCOL_ITEM_DRAMA = ('drama', 13, IntegerType(), False)\nCOL_ITEM_FANTASY = ('fantasy', 14, IntegerType(), False)\nCOL_ITEM_FILMNOIR = ('filmnoir', 15, IntegerType(), False)\nCOL_ITEM_HORROR = ('horror', 16, IntegerType(), False)\nCOL_ITEM_MUSICAL = ('musical', 17, IntegerType(), False)\nCOL_ITEM_MYSTERY = ('mystery', 18, IntegerType(), False)\nCOL_ITEM_ROMACE = ('Romance', 19, IntegerType(), False)\nCOL_ITEM_SCIFI = ('scifi', 20, IntegerType(), False)\nCOL_ITEM_THRILLER = ('thriller', 21, IntegerType(), False)\nCOL_ITEM_WAR = ('war', 22, IntegerType(), False)\nCOL_ITEM_WESTERN = ('western', 23, IntegerType(), False)\nCOL_ITEM_GENEROS = ('generos', None, ArrayType(StringType()), False)\nCOL_ITEM_GENERO = ('genero', None, None, None)\nCOLS_ITEM = (\n    COL_ITEM_ID, \n    COL_ITEM_TITLE,\n    COL_ITEM_RELEASEDATE,\n    COL_ITEM_VIDERELEASEDATE,\n    COL_ITEM_IMDBURL)\nCOLS_ITEM_TODOSGENEROS = (\n    COL_ITEM_UNKNOWN,\n    COL_ITEM_ACTION, \n    COL_ITEM_ADVENTURE,\n    COL_ITEM_ANIMATION,\n    COL_ITEM_CHILDRENS,\n    COL_ITEM_COMEDY,\n    COL_ITEM_CRIME,\n    COL_ITEM_DOCUMENTARY,\n    COL_ITEM_DRAMA,\n    COL_ITEM_FANTASY,\n    COL_ITEM_FILMNOIR,\n    COL_ITEM_HORROR,\n    COL_ITEM_MUSICAL,\n    COL_ITEM_MYSTERY,\n    COL_ITEM_ROMACE,\n    COL_ITEM_SCIFI,\n    COL_ITEM_THRILLER,\n    COL_ITEM_WAR,\n    COL_ITEM_WESTERN)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["___\n## Creación de los dataframes\n\nCreamos los dataframes con las siguientes particularidades:\n\n* **Puntuaciones**: Se elimina el atributo timestamp, ya que no se cree que aporte nada al modelo que queremos construir.\n\n* **Item**: Se eliminarán los atributos video_release_date e IMDb_URL, por la misma razón que anteriormente.\n\nFinalmente uniremos todos los dataframes en uno solo para hacer la modelización."],"metadata":{}},{"cell_type":"code","source":["# Se carga las puntuaciones utilizando COLS_PUNTUACION y después se elimina el timestamp\nesquemaPuntuacion = StructType()\nfor col in COLS_PUNTUACION:\n    esquemaPuntuacion.add(StructField(col[0], col[2], col[3]))\ndataframePuntuacion = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_TABULADOR). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_PUNTUACION, schema=esquemaPuntuacion)\ncabecerasReducidas = list()\n\n# Número de NAN y NULL en rating\nprint('Número de filas con NAN en las puntuaciones en la columna rating: {0}', dataframePuntuacion.where(isnan(COL_PUNTUACION_RATING[0])).count())\nprint('Número de filas con NULL en las puntuaciones en la columna rating: {0}', dataframePuntuacion.where(isnull(COL_PUNTUACION_RATING[0])).count())\n\nfor col in COLS_PUNTUACION:\n    if col[0] != COL_PUNTUACION_TIMESTAMP[0]:\n        cabecerasReducidas.append(col[0])\ndataframePuntuacion = dataframePuntuacion.select(cabecerasReducidas)\n\n# Se carga los usuarios utilizando COLS_USUARIO\nesquemaUsuario = StructType()\nfor col in COLS_USUARIO:\n    esquemaUsuario.add(StructField(col[0], col[2], col[3]))\ndataframeUsuario = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_PIPE). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_USUARIO, schema=esquemaUsuario)\n\n# Se carga los items utilizando COLS_ITEM y COLS_ITEM_TODOSGENEROS\nesquemaItem = StructType()\nfor col in COLS_ITEM:\n    esquemaItem.add(StructField(col[0], col[2], col[3]))\nfor col in COLS_ITEM_TODOSGENEROS:\n    esquemaItem.add(StructField(col[0], col[2], col[3]))\ndataframeItem = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_PIPE). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_ITEM, schema=esquemaItem)\ncabecerasReducidas = list()\nfor col in COLS_ITEM:\n    if col[0] == COL_ITEM_ID[0] or col[0] == COL_ITEM_TITLE[0] or col[0] == COL_ITEM_RELEASEDATE[0]:\n        cabecerasReducidas.append(col[0])\nfor col in COLS_ITEM_TODOSGENEROS:\n    cabecerasReducidas.append(col[0])\ndataframeItem = dataframeItem.select(cabecerasReducidas)\n\n# Se carga los géneros utilizando COLS_GENERO\nesquemaGenero = StructType()\nfor col in COLS_GENERO:\n    esquemaGenero.add(StructField(col[0], col[2], col[3]))\ndataframeGenero = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_PIPE). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_GENERO, schema=esquemaGenero)\n\nprint(dataframePuntuacion.show(4))\nprint(dataframeUsuario.show(4))\nprint(dataframeItem.show(4))\nprint(dataframeGenero.show(4))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Número de filas con NAN en las puntuaciones en la columna rating: {0} 0\nNúmero de filas con NULL en las puntuaciones en la columna rating: {0} 0\n+------+------+------+\nuserid|itemid|rating|\n+------+------+------+\n   196|   242|   3.0|\n   186|   302|   3.0|\n    22|   377|   1.0|\n   244|    51|   2.0|\n+------+------+------+\nonly showing top 4 rows\n\nNone\n+-----------+---+------+----------+-------+\nuser_userid|age|gender|occupation|zipcode|\n+-----------+---+------+----------+-------+\n          1| 24|     M|technician|  85711|\n          2| 53|     F|     other|  94043|\n          3| 23|     M|    writer|  32067|\n          4| 24|     M|technician|  43537|\n+-----------+---+------+----------+-------+\nonly showing top 4 rows\n\nNone\n+-----------+-----------------+-----------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\nitem_itemid|            title|releasedate|unknown|action|adventure|animation|childrens|comedy|crime|documentary|drama|fantasy|filmnoir|horror|musical|mystery|Romance|scifi|thriller|war|western|\n+-----------+-----------------+-----------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\n          1| Toy Story (1995)|01-Jan-1995|      0|     0|        0|        1|        1|     1|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|\n          2| GoldenEye (1995)|01-Jan-1995|      0|     1|        1|        0|        0|     0|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       1|  0|      0|\n          3|Four Rooms (1995)|01-Jan-1995|      0|     0|        0|        0|        0|     0|    0|          0|    0|      0|       0|     0|      0|      0|      0|    0|       1|  0|      0|\n          4|Get Shorty (1995)|01-Jan-1995|      0|     1|        0|        0|        0|     1|    0|          0|    1|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|\n+-----------+-----------------+-----------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\nonly showing top 4 rows\n\nNone\n+---------+-------------+\n     name|genre_genreid|\n+---------+-------------+\n  unknown|            0|\n   Action|            1|\nAdventure|            2|\nAnimation|            3|\n+---------+-------------+\nonly showing top 4 rows\n\nNone\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Creamos el Dataframe completo, basado en los dataframes anteriores a través de las claves, y se divide en Train y Test el dataframe a fin de preparar los datos para el aprendizaje automático, con la división estandar 70/30.\n\nSe utiliza el dataframe completo por la razón de que ofrece una visión mucho más amplia al visualizarlo, pero principalmente porque se obtendrán mejores resultados que con el resto de dataframes, principalmente a que se poseen más datos. Al fin y al cabo, el uso del método de factorización de matriz para matrices de calificación se nutre de la mayor cantidad de productos posibles (long tail), y será de ese modo como podamos obtener un modelo más completo.\n\nSi se tratase de un trabajo más específico, y estuviese orientado a un fin concreto o linea de negocio, se suprimirían los atributos que no aportasen valor, y de esta manera aumentaríamos la eficiencia en la ejecución del programa, así como la capacidad del dataframe de soportar cambios o adiciones de atributos, pero no lo consideraremos así para este ejercicio. En definitiva, el único problema que observaremos utilizando este dataframe será el largo tiempo necesario para ejecutar el modelo"],"metadata":{}},{"cell_type":"code","source":["# Creamos el dataframe completo con un join de los dataframes puntuación-usuario-item:\n\ndataframePuntuacionUsuarioItem = dataframePuntuacion. \\\n                                  join(dataframeUsuario, dataframePuntuacion.userid==dataframeUsuario.user_userid, 'left_outer'). \\\n                                  join(dataframeItem, dataframePuntuacion.itemid==dataframeItem.item_itemid, 'left_outer')\n# Se eliminan las columnas duplicadas\ncabecerasReducidas = list()\nfor col in dataframePuntuacionUsuarioItem.columns:\n    if col != COL_USUARIO_ID[0] and col !=COL_ITEM_ID[0]:\n        cabecerasReducidas.append(col)\ndataframePuntuacionUsuarioItem = dataframePuntuacionUsuarioItem.select(cabecerasReducidas)\n\n# Comprobamos que el dataframe resultante está conforme a lo proyectado:\n\nprint('Columnas del dataframe: {0}', dataframePuntuacionUsuarioItem.columns)\nprint('Número de filas: {0}', dataframePuntuacionUsuarioItem.count())\n\n# Se divide el dataframe en entrenamiento y test\n\ndataframePuntuacionUsuarioItem.cache()\n\ndataframePuntuacionUsuarioItemDividido = dataframePuntuacionUsuarioItem.randomSplit([0.7, 0.3], 1234)\ndataframePuntuacionUsuarioItemEntrenamiento = dataframePuntuacionUsuarioItemDividido[0]\ndataframePuntuacionUsuarioItemTest = dataframePuntuacionUsuarioItemDividido[1]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Columnas del dataframe: {0} [&#39;userid&#39;, &#39;itemid&#39;, &#39;rating&#39;, &#39;age&#39;, &#39;gender&#39;, &#39;occupation&#39;, &#39;zipcode&#39;, &#39;title&#39;, &#39;releasedate&#39;, &#39;unknown&#39;, &#39;action&#39;, &#39;adventure&#39;, &#39;animation&#39;, &#39;childrens&#39;, &#39;comedy&#39;, &#39;crime&#39;, &#39;documentary&#39;, &#39;drama&#39;, &#39;fantasy&#39;, &#39;filmnoir&#39;, &#39;horror&#39;, &#39;musical&#39;, &#39;mystery&#39;, &#39;Romance&#39;, &#39;scifi&#39;, &#39;thriller&#39;, &#39;war&#39;, &#39;western&#39;]\nNúmero de filas: {0} 100000\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["## Implementación del modelo ALS\n\nPara crear el modelo se utilizará CrossValidator, en el que se variarán varios parámetros: rank, maxIter, alpha y regParam, dentro de unos márgenes normalizados y estándares, que tras varios intentos resultan ofrecer el cálculo del modelo ALS sin aumentar excesivamente el consumo de recursos.\n\nLa premisa principal que justifica el uso del CrossValidator es que se ha comprobado que, bajo los parámetros escogidos, sólo un 0,20% de las entradas del dataset del test no tienen valor, y eliminarlos (que es nuestra pretensión), bien puede suponerse que no afectaría en absoluto al modelo, y nos garantizaría evitar tener Nan para el cálculo de la Raíz del error cuadrático medio (rmse)."],"metadata":{}},{"cell_type":"code","source":["# Evaluador y cross validation\nevaluatorRegression = RegressionEvaluator(labelCol=COL_PUNTUACION_RATING[0])\n\nals = ALS(userCol=COL_PUNTUACION_USERID[0], itemCol=COL_PUNTUACION_ITEMID[0], ratingCol=COL_PUNTUACION_RATING[0], coldStartStrategy='drop')\n# als = ALS(userCol=COL_PUNTUACION_USERID[0], itemCol=COL_PUNTUACION_ITEMID[0], ratingCol=COL_PUNTUACION_RATING[0])\ngrid = ParamGridBuilder(). \\\n        addGrid(als.rank, [5, 10, 15, 20]). \\\n        addGrid(als.maxIter, [5, 10]). \\\n        addGrid(als.alpha, [1.0, 2.0]). \\\n        addGrid(als.regParam, [0.1, 0.5, 1.0]). \\\n        build()\n# grid = ParamGridBuilder().addGrid(als.rank, [5, 20]).build()\ncrossValidator = CrossValidator(estimator=als, estimatorParamMaps=grid, evaluator=evaluatorRegression, numFolds=2)\ncrossValidatorModel = crossValidator.fit(dataframePuntuacionUsuarioItemEntrenamiento)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["## Valoración del modelo\n\nDescribimos el método de predicción y valoramos que, efectivamente, no existen NaN en el modelo propuesto gracias al CrossValidation aplicado anteriormente."],"metadata":{}},{"cell_type":"code","source":["# Se obtiene la predicción para entrenamiento y test\n\ndataframePuntuacionUsuarioItemEntrenamientoPrediccion = crossValidatorModel.bestModel.transform(dataframePuntuacionUsuarioItemEntrenamiento)\ndataframePuntuacionUsuarioItemTestPrediccion = crossValidatorModel.bestModel.transform(dataframePuntuacionUsuarioItemTest)\n\ndataframePuntuacionUsuarioItemEntrenamiento.show(5)\n\n# Se muestra el número de filas y las que son NAN en el conjunto de entrenamiento y de test\n\nprint('Conjunto de entrenamiento predicción -> Número de filas: {0}, número con NAN en predicción: {1}'.format(dataframePuntuacionUsuarioItemEntrenamientoPrediccion.count(), dataframePuntuacionUsuarioItemEntrenamientoPrediccion.where(isnan(COL_PUNTUACION_PREDICTION[0])).count()))\nprint('Conjunto de test predicción -> Número de filas: {0}, número con NAN en predicción: {1}'.format(dataframePuntuacionUsuarioItemTestPrediccion.count(), dataframePuntuacionUsuarioItemTestPrediccion.where(isnan(COL_PUNTUACION_PREDICTION[0])).count()))\n\n# Describe método para rating y prediction\n\nprint(dataframePuntuacionUsuarioItemEntrenamientoPrediccion.select(COL_PUNTUACION_RATING[0], COL_PUNTUACION_PREDICTION[0]).describe().show())\nprint(dataframePuntuacionUsuarioItemTestPrediccion.select(COL_PUNTUACION_RATING[0], COL_PUNTUACION_PREDICTION[0]).describe().show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+------+------+---+------+----------+-------+--------------------+-----------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\nuserid|itemid|rating|age|gender|occupation|zipcode|               title|releasedate|unknown|action|adventure|animation|childrens|comedy|crime|documentary|drama|fantasy|filmnoir|horror|musical|mystery|Romance|scifi|thriller|war|western|\n+------+------+------+---+------+----------+-------+--------------------+-----------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\n     1|     4|   3.0| 24|     M|technician|  85711|   Get Shorty (1995)|01-Jan-1995|      0|     1|        0|        0|        0|     1|    0|          0|    1|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|\n     1|     5|   3.0| 24|     M|technician|  85711|      Copycat (1995)|01-Jan-1995|      0|     0|        0|        0|        0|     0|    1|          0|    1|      0|       0|     0|      0|      0|      0|    0|       1|  0|      0|\n     1|     6|   5.0| 24|     M|technician|  85711|Shanghai Triad (Y...|01-Jan-1995|      0|     0|        0|        0|        0|     0|    0|          0|    1|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|\n     1|     7|   4.0| 24|     M|technician|  85711|Twelve Monkeys (1...|01-Jan-1995|      0|     0|        0|        0|        0|     0|    0|          0|    1|      0|       0|     0|      0|      0|      0|    1|       0|  0|      0|\n     1|     8|   1.0| 24|     M|technician|  85711|         Babe (1995)|01-Jan-1995|      0|     0|        0|        0|        1|     1|    0|          0|    1|      0|       0|     0|      0|      0|      0|    0|       0|  0|      0|\n+------+------+------+---+------+----------+-------+--------------------+-----------+-------+------+---------+---------+---------+------+-----+-----------+-----+-------+--------+------+-------+-------+-------+-----+--------+---+-------+\nonly showing top 5 rows\n\nConjunto de entrenamiento predicción -&gt; Número de filas: 70126, número con NAN en predicción: 0\nConjunto de test predicción -&gt; Número de filas: 29817, número con NAN en predicción: 0\n+-------+------------------+------------------+\nsummary|            rating|        prediction|\n+-------+------------------+------------------+\n  count|             70126|             70126|\n   mean|3.5312437612297862|3.4081050159234176|\n stddev|1.1264763411424088|0.7071796967280013|\n    min|               1.0|         0.2048777|\n    max|               5.0|          5.757818|\n+-------+------------------+------------------+\n\nNone\n+-------+-----------------+------------------+\nsummary|           rating|        prediction|\n+-------+-----------------+------------------+\n  count|            29817|             29817|\n   mean|3.528155079317168|3.3988192242592055|\n stddev|1.122772872442184|0.7050247747441143|\n    min|              1.0|        -0.5108311|\n    max|              5.0|         5.7307315|\n+-------+-----------------+------------------+\n\nNone\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["**RMSE** para el conjunto de entrenamiento y el de test. Como se puede observar es más pequeño el Train que el Test, como es lógico. Llama la atención que son valores relativamente altos si los consideramos en el rango 0-1."],"metadata":{}},{"cell_type":"code","source":["# Se obtiene el RMSE sobre los dos conjuntos\nrmseEntrenamiento = evaluatorRegression.evaluate(dataframePuntuacionUsuarioItemEntrenamientoPrediccion, {evaluatorRegression.metricName: 'rmse'})\nrmseTest = evaluatorRegression.evaluate(dataframePuntuacionUsuarioItemTestPrediccion, {evaluatorRegression.metricName: 'rmse'})\n\nprint('RMSE en training: {0}'.format(rmseEntrenamiento))\nprint('RMSE en test: {0}'.format(rmseTest))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">RMSE en training: 0.8016410428223212\nRMSE en test: 0.9280585419449354\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["Se observa en un gráfico la comparativa de las puntuaciones reales y según modelo:\n\n* Se observa que, como en cierto modo es lógico, el modelo no se ajusta a la línea oblicua que debería de seguir. Si observáramos los resultados en un boxplots veríamos que la aparente diferencia del modelo continuo predicho que hemos construido y la evolución real(como ya vimos anteriormente, el error del dataset de entrenamiento es menor),  veríamos que la densidad de puntos es mucho mayor en torno a la zona que rodea la recta que los puntos que se dispersan en su vertical. \n\n** Se podría jugar con los parámetros del modelo ALS y también haciendo una limpieza previa de datos, para eliminar outliers."],"metadata":{}},{"cell_type":"code","source":["# Se crea la lista con la puntuación real y la predicha en Train y Test\n\nxEntrenamiento, yEntrenamiento = list(), list()\nfor entrenamientoPrediccion in dataframePuntuacionUsuarioItemEntrenamientoPrediccion.collect():\n    xEntrenamiento.append(entrenamientoPrediccion[COL_PUNTUACION_RATING[0]])\n    yEntrenamiento.append(entrenamientoPrediccion[COL_PUNTUACION_PREDICTION[0]])\n    \nxTest, yTest = list(), list()\nfor testPrediccion in dataframePuntuacionUsuarioItemTestPrediccion.collect():\n    xTest.append(testPrediccion[COL_PUNTUACION_RATING[0]])\n    yTest.append(testPrediccion[COL_PUNTUACION_PREDICTION[0]])\n\n# Ploteamos\n\nplt.clf()\nplt.xlim(-1, 6)\nplt.ylim(-1, 6)\nplt.xlabel('Puntuacion real')\nplt.ylabel('Puntuacion segun el modelo')\nplt.title('Puntuacion real vs prediccion')\n\nplt.plot([0, 20], [0, 20], 'b')\n# Se pasan los datos de entrenamiento y test al gráfico\n\nplt.plot(xTest, yTest, 'ro', label='Test')\nplt.legend(loc='lower right')\n\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["plt.clf()\nplt.xlim(-1, 6)\nplt.ylim(-1, 6)\nplt.xlabel('Puntuacion real')\nplt.ylabel('Puntuacion segun el modelo')\nplt.title('Puntuacion real vs prediccion')\n\nplt.plot([0, 20], [0, 20], 'b')\n# Se pasan los datos de entrenamiento y test al gráfico\nplt.plot(xEntrenamiento, yEntrenamiento, 'go', label='Train')\n\nplt.legend(loc='lower right')\n\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["## Análisis de datos"],"metadata":{}},{"cell_type":"markdown","source":["### Género de películas mejor valorados\nSe obtendrá un dataframe donde cada fila tendrá los valores item_id-película-género. Por cada película, habrá tantas filas como géneros tenga.\n\nPara ello:\n1. Se obtendrá un diccionario con los géneros donde la clave es el id o posición en el fichero de item y el valor será el género.\n2. El siguiente paso es añadir una columna con un array con los géneros que tiene cada película. Para ello se utilizará RDDs para posteriormente trasformalo en otro dataframe\n3. El último paso es hacer un explode."],"metadata":{}},{"cell_type":"code","source":["def trasformarFilaColumnasgeneroColumageneros(fila, diccionarionGenero, ultimoIndiceNoGenero=1):\n\n    indice = 0\n    indiceGenero = 0\n    lineaNueva = list()\n    generos = list()\n    for item in fila:\n        if indice>ultimoIndiceNoGenero:\n            if item==1:\n                genero = diccionarionGenero.get(indiceGenero)\n                if genero:\n                    generos.append(genero)\n            indiceGenero += 1\n        else:\n            lineaNueva.append(item)\n        indice += 1\n    lineaNueva.append(generos)\n    return lineaNueva\n  \n# Se crea un diccionario con los géneros donde la clave es la columna id y el valor el nombre del género\n\ndiccionarioGenero = dict()\nfor row in dataframeGenero.collect():\n    diccionarioGenero[row.genre_genreid] = row.name\nprint(diccionarioGenero)\n\n# Se obtiene el nombre de todas las columnas de los géneros en el dataframe de item\n\ncolumnas = list()\ncolumnas.append(COL_ITEM_ID[0])\ncolumnas.append(COL_ITEM_TITLE[0])\nfor col in COLS_ITEM_TODOSGENEROS:\n    columnas.append(col[0])\n    \n# Seleccionamos sólo itemid, titulo, generos\n\ndataframeItemGenero = dataframeItem.select(columnas)\nrddItemGenero = dataframeItemGenero.rdd.map(lambda fila: trasformarFilaColumnasgeneroColumageneros(fila, diccionarionGenero=diccionarioGenero))\n\n# Se crea el dataframe desde el RDD\n\ncolumnas = list()\ncolumnas.append(COL_ITEM_ID[0])\ncolumnas.append(COL_ITEM_TITLE[0])\ncolumnas.append(COL_ITEM_GENEROS[0])\ndataframeItemGenero = rddItemGenero.toDF(columnas)\n\n# Hacemos 'explode' para distribuir todas las categorias en filas, y posteriormente comparamos el número de filas\n\ndataframeItemGenero = dataframeItemGenero.select(COL_ITEM_ID[0], COL_ITEM_TITLE[0], explode(dataframeItemGenero.generos).alias(COL_ITEM_GENERO[0]))\n\nprint('Nº filas antes de explode {0} y después {1}'.format(dataframeItem.count(), dataframeItemGenero.count()))\n\ndataframeItemGenero.cache()\n\ndataframeItemGenero.show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{0: &#39;unknown&#39;, 1: &#39;Action&#39;, 2: &#39;Adventure&#39;, 3: &#39;Animation&#39;, 4: &#34;Children&#39;s&#34;, 5: &#39;Comedy&#39;, 6: &#39;Crime&#39;, 7: &#39;Documentary&#39;, 8: &#39;Drama&#39;, 9: &#39;Fantasy&#39;, 10: &#39;Film-Noir&#39;, 11: &#39;Horror&#39;, 12: &#39;Musical&#39;, 13: &#39;Mystery&#39;, 14: &#39;Romance&#39;, 15: &#39;Sci-Fi&#39;, 16: &#39;Thriller&#39;, 17: &#39;War&#39;, 18: &#39;Western&#39;}\nNº filas antes de explode 1682 y después 2893\n+-----------+-----------------+----------+\nitem_itemid|            title|    genero|\n+-----------+-----------------+----------+\n          1| Toy Story (1995)| Animation|\n          1| Toy Story (1995)|Children&#39;s|\n          1| Toy Story (1995)|    Comedy|\n          2| GoldenEye (1995)|    Action|\n          2| GoldenEye (1995)| Adventure|\n          2| GoldenEye (1995)|  Thriller|\n          3|Four Rooms (1995)|  Thriller|\n          4|Get Shorty (1995)|    Action|\n          4|Get Shorty (1995)|    Comedy|\n          4|Get Shorty (1995)|     Drama|\n+-----------+-----------------+----------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["Se transforma el dataframe del Test sustituyendo filas por el dataframe que se acaba de generar"],"metadata":{}},{"cell_type":"code","source":["cabecerasReducidas = list()\n\nfor col in COLS_PUNTUACION:\n    if col[0] != COL_PUNTUACION_TIMESTAMP[0]:\n        cabecerasReducidas.append(col[0])\nfor col in COLS_USUARIO:\n    if col[0] != COL_USUARIO_ID[0]:\n        cabecerasReducidas.append(col[0])\n        \ncabecerasReducidas.append(COL_PUNTUACION_PREDICTION[0])\n\ndataframePuntuacionUsuarioItemTestPrediccionGenero = dataframePuntuacionUsuarioItemTestPrediccion.select(cabecerasReducidas)\n\n# Se hace el join con el otro dataframe y se elimina itemid\n\ndataframePuntuacionUsuarioItemTestPrediccionGenero = dataframePuntuacionUsuarioItemTestPrediccionGenero.join(dataframeItemGenero, dataframePuntuacionUsuarioItemTestPrediccionGenero.itemid==dataframeItemGenero.item_itemid, 'inner')\n\nprint('Número de filas antes en el conjunto de test antes de hacer el join {0} y después {1}'.format(dataframePuntuacionUsuarioItemTestPrediccion.count(), dataframePuntuacionUsuarioItemTestPrediccionGenero.count()))\n\ndataframeItemGenero.unpersist()\ndataframePuntuacionUsuarioItemTestPrediccionGenero.cache()\n\ndataframePuntuacionUsuarioItemTestPrediccionGenero.show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Número de filas antes en el conjunto de test antes de hacer el join 29817 y después 63496\n+------+------+------+---+------+-------------+-------+----------+-----------+--------------------+------+\nuserid|itemid|rating|age|gender|   occupation|zipcode|prediction|item_itemid|               title|genero|\n+------+------+------+---+------+-------------+-------+----------+-----------+--------------------+------+\n   243|    26|   3.0| 33|     M|     educator|  60201|  3.195533|         26|Brothers McMullen...|Comedy|\n   593|    26|   4.0| 31|     F|     educator|  68767| 3.2315865|         26|Brothers McMullen...|Comedy|\n   436|    26|   3.0| 30|     F|administrator|  17345| 3.5340867|         26|Brothers McMullen...|Comedy|\n   406|    26|   3.0| 52|     M|     educator|  93109| 3.1100733|         26|Brothers McMullen...|Comedy|\n   336|    26|   5.0| 23|     M|     salesman|  42101| 3.3243408|         26|Brothers McMullen...|Comedy|\n   707|    26|   3.0| 56|     F|    librarian|  19146| 3.3416667|         26|Brothers McMullen...|Comedy|\n   222|    26|   3.0| 29|     M|   programmer|  27502| 3.0283246|         26|Brothers McMullen...|Comedy|\n   886|    26|   4.0| 20|     M|      student|  61820| 2.8934784|         26|Brothers McMullen...|Comedy|\n   327|    26|   3.0| 22|     M|      student|  11101| 3.0975115|         26|Brothers McMullen...|Comedy|\n   318|    26|   5.0| 65|     M|      retired|  06518| 3.5815697|         26|Brothers McMullen...|Comedy|\n+------+------+------+---+------+-------------+-------+----------+-----------+--------------------+------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["Valoración de películas por genéro: Para valorar los géneros mejor valorados, vamos a hacer una consulta con las medias de rating y predicción por género"],"metadata":{}},{"cell_type":"code","source":["print(dataframePuntuacionUsuarioItemTestPrediccionGenero.groupBy(COL_ITEM_GENERO[0]).agg(avg(COL_PUNTUACION_RATING[0]).alias(COL_PUNTUACION_RATING[0]), avg(COL_PUNTUACION_PREDICTION[0]).alias(COL_PUNTUACION_PREDICTION[0]), count('*').alias(COL_PUNTUACION_NUMEROPUNTUACIONES[0])).sort(COL_PUNTUACION_RATING[0], ascending=False).show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+------------------+------------------+-------------------+\n     genero|            rating|        prediction|numero_puntuaciones|\n+-----------+------------------+------------------+-------------------+\n  Film-Noir| 3.949044585987261|3.7403907603772075|                471|\n        War|3.8166318719554626|3.6786669243435606|               2874|\n      Drama|3.6908005381769255|3.5557855231906084|              11892|\n    Mystery|3.6447368421052633|3.4796821794031483|               1520|\n      Crime|3.6419031719532553|3.4846138363091494|               2396|\n    Romance| 3.634884534639608|3.5076095221747963|               5716|\nDocumentary|             3.625|3.5093206932832457|                232|\n    Western| 3.613259668508287|3.5009253349971594|                543|\n  Animation| 3.552583025830258|3.4494669570474166|               1084|\n     Sci-Fi|3.5469627360898417|3.4380775368931706|               3918|\n    Musical| 3.535614525139665| 3.406676713835094|               1432|\n   Thriller|3.4972434915773354|3.3655292038302327|               6530|\n     Action|3.4837329876863254|3.3605296531476068|               7715|\n  Adventure|3.4790911288373216|  3.39731672747659|               4137|\n     Comedy|3.4054633705835875|3.2607506290052934|               8859|\n     Horror|3.3407544836116263| 3.162789779824096|               1617|\n    unknown|3.3333333333333335| 3.273937463760376|                  3|\n Children&#39;s| 3.318625174175569| 3.232146858601475|               2153|\n    Fantasy| 3.198019801980198| 3.125619927845379|                404|\n+-----------+------------------+------------------+-------------------+\n\nNone\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["Film-noir es el género que tiene mejor valoración, pero hace sospechar el hecho de que es uno de los géneros menos votados, lo que significa que está orientado a un público más exclusivo, y esto podría, según como decíamos en los inicios, no ser un análisis suficiente o concluyente si el fin último fuera aumentar beneficios generando contenido basado en género. \n\nDadas esas circunstancias, valoraremos de nuevo el ranking eliminando aquellas cuyo número de puntiaciones esté por debajo de 1000:"],"metadata":{}},{"cell_type":"code","source":["dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup= dataframePuntuacionUsuarioItemTestPrediccionGenero.groupBy(COL_ITEM_GENERO[0]).agg(avg(COL_PUNTUACION_RATING[0]).alias(COL_PUNTUACION_RATING[0]), avg(COL_PUNTUACION_PREDICTION[0]).alias(COL_PUNTUACION_PREDICTION[0]), count('*').alias(COL_PUNTUACION_NUMEROPUNTUACIONES[0]))\n\nprint(dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup.where(dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup.numero_puntuaciones>1000).sort(COL_PUNTUACION_RATING[0], ascending=False).show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+------------------+------------------+-------------------+\n    genero|            rating|        prediction|numero_puntuaciones|\n+----------+------------------+------------------+-------------------+\n       War|3.8166318719554626|3.6786669243435606|               2874|\n     Drama|3.6908005381769255|3.5557855231906084|              11892|\n   Mystery|3.6447368421052633|3.4796821794031483|               1520|\n     Crime|3.6419031719532553|3.4846138363091494|               2396|\n   Romance| 3.634884534639608|3.5076095221747963|               5716|\n Animation| 3.552583025830258|3.4494669570474166|               1084|\n    Sci-Fi|3.5469627360898417|3.4380775368931706|               3918|\n   Musical| 3.535614525139665| 3.406676713835094|               1432|\n  Thriller|3.4972434915773354|3.3655292038302327|               6530|\n    Action|3.4837329876863254|3.3605296531476068|               7715|\n Adventure|3.4790911288373216|  3.39731672747659|               4137|\n    Comedy|3.4054633705835875|3.2607506290052934|               8859|\n    Horror|3.3407544836116263| 3.162789779824096|               1617|\nChildren&#39;s| 3.318625174175569| 3.232146858601475|               2153|\n+----------+------------------+------------------+-------------------+\n\nNone\n</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["Y como se puede comprobar, es el género de guerra quien gana en mayor rating. \n\nSe podría hacer también una agrupación por **género y código postal** para ver si en una zona predomina las buenas puntuaciones de un determinado género, filtrando aquellas que tengan un número mínimo de puntuaciones mayor que 50."],"metadata":{}},{"cell_type":"code","source":["dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup = dataframePuntuacionUsuarioItemTestPrediccionGenero.groupBy([COL_ITEM_GENERO[0], COL_USUARIO_ZIPCODE[0]]).agg(avg(COL_PUNTUACION_RATING[0]).alias(COL_PUNTUACION_RATING[0]), avg(COL_PUNTUACION_PREDICTION[0]).alias(COL_PUNTUACION_PREDICTION[0]), count('*').alias(COL_PUNTUACION_NUMEROPUNTUACIONES[0]))\n\nprint(dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup.where(dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup.numero_puntuaciones>50).sort(COL_PUNTUACION_RATING[0], ascending=False).show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------+------------------+------------------+-------------------+\n  genero|zipcode|            rating|        prediction|numero_puntuaciones|\n+--------+-------+------------------+------------------+-------------------+\n   Drama|  97520| 4.134615384615385|3.9813398523972583|                 52|\n   Drama|  92626| 4.109589041095891|  3.82917049812944|                 73|\n   Drama|  11758|3.9863013698630136|3.8211512957533746|                 73|\n   Drama|  48197|3.9607843137254903| 3.637568908579209|                 51|\n   Drama|  02215|3.9019607843137254|3.6423270982854508|                 51|\n   Drama|  14216|3.8679245283018866| 3.581475055442666|                 53|\n   Drama|  48103|            3.8625| 3.620722621679306|                 80|\n   Drama|  83702|3.7857142857142856|3.7061876910073415|                 56|\n   Drama|  55414| 3.763358778625954|3.5315960591075983|                131|\n   Drama|  80525|3.7209302325581395|3.5106907278992407|                 86|\n  Action|  61820|3.6538461538461537|3.4510942628750434|                 52|\n   Drama|  29206|3.6527777777777777|3.3148333215051227|                 72|\n   Drama|  10003|3.6464646464646466| 3.571312640652512|                 99|\n  Comedy|  48103|3.6444444444444444| 3.401814309755961|                 90|\n Romance|  55414| 3.641509433962264|3.3802655193040954|                 53|\n   Drama|  20009|              3.64|3.5963089799880983|                100|\nThriller|  55414| 3.617283950617284|3.3895504003689614|                 81|\n   Drama|  61820| 3.616279069767442| 3.538461496663648|                 86|\n  Action|  55414|3.5795454545454546| 3.296123272993348|                 88|\n  Comedy|  80525| 3.566265060240964|3.3144876956939697|                 83|\n+--------+-------+------------------+------------------+-------------------+\nonly showing top 20 rows\n\nNone\n</div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["### Películas mejor valoradas\nAl igual que con el género, se valoran el número de películas mejor valoradas por título:"],"metadata":{}},{"cell_type":"code","source":["dataframePuntuacionUsuarioItemTestPrediccionGroup = dataframePuntuacionUsuarioItemTestPrediccion.groupBy(COL_ITEM_TITLE[0]).agg(avg(COL_PUNTUACION_RATING[0]).alias(COL_PUNTUACION_RATING[0]), avg(COL_PUNTUACION_PREDICTION[0]).alias(COL_PUNTUACION_PREDICTION[0]), count('*').alias(COL_PUNTUACION_NUMEROPUNTUACIONES[0]))\nprint(dataframePuntuacionUsuarioItemTestPrediccionGroup.where(dataframePuntuacionUsuarioItemTestPrediccionGroup.numero_puntuaciones>60).sort(COL_PUNTUACION_RATING[0], ascending=False).show())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------------------+------------------+-------------------+\n               title|            rating|        prediction|numero_puntuaciones|\n+--------------------+------------------+------------------+-------------------+\nSchindler&#39;s List ...| 4.455555555555556| 4.278086402681139|                 90|\n   Casablanca (1942)| 4.436619718309859| 4.346449049425797|                 71|\n    Star Wars (1977)| 4.427807486631016| 4.224509615311648|                187|\nOne Flew Over the...| 4.414285714285715|   4.1923647914614|                 70|\nShawshank Redempt...| 4.411111111111111| 4.177539041307237|                 90|\nGodfather, The (1...| 4.325581395348837|  4.02985154381094|                129|\nDr. Strangelove o...| 4.311475409836065| 4.157566692008347|                 61|\nUsual Suspects, T...| 4.305882352941176| 4.189605886795942|                 85|\n   Braveheart (1995)| 4.301204819277109| 4.018423089061875|                 83|\nGodfather: Part I...|  4.27027027027027|4.0521568672077075|                 74|\nGood Will Hunting...|  4.26984126984127| 4.205939058273557|                 63|\n      Titanic (1997)| 4.262135922330097| 4.061602395715066|                103|\n      Amadeus (1984)| 4.252747252747253| 4.013721057346889|                 91|\nSilence of the La...|             4.224| 4.120173648834228|                125|\nPrincess Bride, T...| 4.212765957446808| 4.033322428135162|                 94|\nMonty Python and ...| 4.206521739130435|3.8568470776081085|                 92|\n        Alien (1979)| 4.197530864197531| 3.879824123264831|                 81|\nWizard of Oz, The...| 4.191780821917808| 3.944918100148031|                 73|\nTo Kill a Mocking...|4.1911764705882355| 4.101320687462302|                 68|\nEmpire Strikes Ba...| 4.177570093457944| 4.066192127833856|                107|\n+--------------------+------------------+------------------+-------------------+\nonly showing top 20 rows\n\nNone\n</div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["La lista de Schindler, Casablanca, Star Wars, Alguien voló sobre el nido del cuco.... \n\nPese a que el análisis podría complejizarse mucho más, lo interesante es que vemos que la pridicción se ajusta bastante bien a los resultados por agrupación, aunque un poco por debajo"],"metadata":{}}],"metadata":{"name":"Motor de recomendación con PySpark","notebookId":2287120434497422},"nbformat":4,"nbformat_minor":0}
